{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e02757857f754f6d841abac3b3fbd387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e4ce9e48f234e9c83cb4fdbdbb6305a",
              "IPY_MODEL_41d0a4bd74674365a149ef62d02c6008",
              "IPY_MODEL_b054971c6a8a435294835a3702ec9ecb"
            ],
            "layout": "IPY_MODEL_46b649a9784241f29ac366d400992661"
          }
        },
        "1e4ce9e48f234e9c83cb4fdbdbb6305a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc83bb81f51408ca1543406afbc53dc",
            "placeholder": "​",
            "style": "IPY_MODEL_931f95a4721143398d80acfba08726dc",
            "value": "  0%"
          }
        },
        "41d0a4bd74674365a149ef62d02c6008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bb054353d24d50b8aa9d1e480e1a7a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a264e416ab004ead9c504346c0a32dc7",
            "value": 0
          }
        },
        "b054971c6a8a435294835a3702ec9ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed3cac6d3c3e4a9a99db0c9a88a557bd",
            "placeholder": "​",
            "style": "IPY_MODEL_18ca23e7c75b4ebd8618f5afc1faae4b",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "46b649a9784241f29ac366d400992661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc83bb81f51408ca1543406afbc53dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931f95a4721143398d80acfba08726dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37bb054353d24d50b8aa9d1e480e1a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a264e416ab004ead9c504346c0a32dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed3cac6d3c3e4a9a99db0c9a88a557bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ca23e7c75b4ebd8618f5afc1faae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ6p8pcJQKPw",
        "outputId": "2cff08b9-3de6-49b5-c418-4f80a051a815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'da-tacos'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 112 (delta 6), reused 6 (delta 6), pack-reused 105 (from 1)\u001b[K\n",
            "Receiving objects: 100% (112/112), 29.62 KiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MTG/da-tacos.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('da-tacos')"
      ],
      "metadata": {
        "id": "R8V5L47rQQ-c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shwl5-bnQY4F",
        "outputId": "ac1e0f00-a6f6-4f05-d4d5-7a0a25969779"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepdish (from -r requirements.txt (line 1))\n",
            "  Downloading deepdish-0.3.7-py2.py3-none-any.whl.metadata (856 bytes)\n",
            "Collecting wget (from -r requirements.txt (line 2))\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepdish->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deepdish->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.11/dist-packages (from deepdish->-r requirements.txt (line 1)) (3.10.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 3)) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 3)) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables->deepdish->-r requirements.txt (line 1)) (2.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tables->deepdish->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables->deepdish->-r requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables->deepdish->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->blosc2>=2.3.0->tables->deepdish->-r requirements.txt (line 1)) (1.3.1)\n",
            "Downloading deepdish-0.3.7-py2.py3-none-any.whl (37 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a4995c6e5a69a26d319e38b17a62b896c5bd47edd1e1d13dba591adaa81ecb0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, deepdish\n",
            "Successfully installed deepdish-0.3.7 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running directly from Colab UI\n",
        "os.makedirs('/content/coveranalysis_single_files_output', exist_ok=True)\n",
        "!python3 download_da-tacos.py --dataset coveranalysis --type single_files --source gdrive --outputdir /content/coveranalysis_single_files_output\n",
        "!unzip /content/coveranalysis_single_files_output/da-tacos_coveranalysis_subset_single_files.zip -d /content/coveranalysis_single_files_output\n"
      ],
      "metadata": {
        "id": "x8i821lPQcut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running through my gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/da-tacos_coveranalysis_subset_single_files.zip -d /content/drive/MyDrive/datacos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqciJAUTRuk6",
        "outputId": "a9520a4d-d28e-458e-d803-61ed31684d13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/MyDrive/da-tacos_coveranalysis_subset_single_files.zip\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Necessary Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "v6si1C_pRbow"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfYU2RplSt0y",
        "outputId": "46ce30c1-8925-4e7c-bae2-64a0aaf6366e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Class - Creating pairs with labels Y=0 and Y=1 and returns a compined tensor\n",
        "\n",
        "import deepdish as dd\n",
        "\n",
        "class DATACOSDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Initialize the dataset by reading in the pairs from the directory structure.\n",
        "        Each subfolder contains 2 cover-related songs, and you create pairs with labels.\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.pairs = []  # Will store (song1, song2, label)\n",
        "        self.subfolders = [f.path for f in os.scandir(data_dir) if f.is_dir()]\n",
        "\n",
        "        # Generate pairs with label Y=0 (cover-related)\n",
        "        for folder in self.subfolders:\n",
        "            songs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.h5')]\n",
        "            if len(songs) == 2:  # Assumption: each folder contains exactly 2 songs\n",
        "                cover, original = songs\n",
        "                self.pairs.append((cover, original, 0))  # Y=0 for similar pairs (cover-related)\n",
        "\n",
        "        # Generate non-cover pairs with label Y=1\n",
        "        all_songs_by_folder = {folder: [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.h5')] for folder in self.subfolders}\n",
        "\n",
        "        for _ in range(len(self.pairs)):  # Generate the same number of non-cover pairs\n",
        "            # Randomly sample two different subfolders\n",
        "            folder1, folder2 = random.sample(self.subfolders, 2)  # Ensure two different subfolders\n",
        "            song1 = random.choice(all_songs_by_folder[folder1])\n",
        "            song2 = random.choice(all_songs_by_folder[folder2])\n",
        "\n",
        "            self.pairs.append((song1, song2, 1))  # Y=1 for non-similar pairs (not cover-related)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        song1_path, song2_path, label = self.pairs[idx]\n",
        "\n",
        "        # Load the .h5 files\n",
        "        song1_data = self.load_h5(song1_path)\n",
        "        song2_data = self.load_h5(song2_path)\n",
        "\n",
        "        if self.transform:\n",
        "            song1_data = self.transform(song1_data)\n",
        "            song2_data = self.transform(song2_data)\n",
        "\n",
        "        return song1_data, song2_data, torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def load_h5(self, file_path):\n",
        "        \"\"\"\n",
        "        Helper function to load the .h5 file and return a tensor combining the features.\n",
        "        \"\"\"\n",
        "        # Load the .h5 file using deepdish\n",
        "        data = dd.io.load(file_path)\n",
        "\n",
        "        # Extract all requested features\n",
        "        chroma_cens_data = data.get('chroma_cens', None)\n",
        "        crema_data = data.get('crema', None)\n",
        "        hpcp_data = data.get('hpcp', None)\n",
        "        key_extractor_data = data.get('key_extractor', None)\n",
        "        madmom_features_data = data.get('madmom_features', None)\n",
        "        mfcc_htk_data = data.get('mfcc_htk', None)\n",
        "        tags_data = data.get('tags', None)\n",
        "        label_data = data.get('label', None)\n",
        "\n",
        "        feature_list = []\n",
        "\n",
        "        # Append the features (ensure they are tensors)\n",
        "        if chroma_cens_data is not None:\n",
        "            chroma_cens_data = torch.tensor(chroma_cens_data, dtype=torch.float)\n",
        "            if chroma_cens_data.dim() == 1:\n",
        "                chroma_cens_data = chroma_cens_data.unsqueeze(-1)  # Reshape to 2D if necessary\n",
        "            feature_list.append(chroma_cens_data)\n",
        "        if crema_data is not None:\n",
        "            crema_data = torch.tensor(crema_data, dtype=torch.float)\n",
        "            if crema_data.dim() == 1:\n",
        "                crema_data = crema_data.unsqueeze(-1)  # Reshape to 2D if necessary\n",
        "            feature_list.append(crema_data)\n",
        "        if hpcp_data is not None:\n",
        "            hpcp_data = torch.tensor(hpcp_data, dtype=torch.float)\n",
        "            if hpcp_data.dim() == 1:\n",
        "                hpcp_data = hpcp_data.unsqueeze(-1)  # Reshape to 2D if necessary\n",
        "            feature_list.append(hpcp_data)\n",
        "\n",
        "        # Handle the key_extractor_data (if it's a dictionary, extract relevant data)\n",
        "        if key_extractor_data is not None:\n",
        "            if isinstance(key_extractor_data, dict):\n",
        "                key_extractor_values = key_extractor_data.get('tonnetz', None)  # Adjust based on actual structure\n",
        "                if key_extractor_values is not None:\n",
        "                    key_extractor_values = torch.tensor(key_extractor_values, dtype=torch.float)\n",
        "                    if key_extractor_values.dim() == 1:\n",
        "                        key_extractor_values = key_extractor_values.unsqueeze(-1)\n",
        "                    feature_list.append(key_extractor_values)\n",
        "            else:\n",
        "                key_extractor_data = torch.tensor(key_extractor_data, dtype=torch.float)\n",
        "                if key_extractor_data.dim() == 1:\n",
        "                    key_extractor_data = key_extractor_data.unsqueeze(-1)\n",
        "                feature_list.append(key_extractor_data)\n",
        "\n",
        "        # Handle madmom_features_data (if it's a dictionary, extract relevant data)\n",
        "        if madmom_features_data is not None:\n",
        "            if isinstance(madmom_features_data, dict):\n",
        "                madmom_values = madmom_features_data.get('tempo', None)  # Adjust key based on actual structure\n",
        "                if madmom_values is not None:\n",
        "                    madmom_values = torch.tensor(madmom_values, dtype=torch.float)\n",
        "                    if madmom_values.dim() == 1:\n",
        "                        madmom_values = madmom_values.unsqueeze(-1)\n",
        "                    feature_list.append(madmom_values)\n",
        "            else:\n",
        "                madmom_features_data = torch.tensor(madmom_features_data, dtype=torch.float)\n",
        "                if madmom_features_data.dim() == 1:\n",
        "                    madmom_features_data = madmom_features_data.unsqueeze(-1)\n",
        "                feature_list.append(madmom_features_data)\n",
        "\n",
        "        if mfcc_htk_data is not None:\n",
        "            mfcc_htk_data = torch.tensor(mfcc_htk_data, dtype=torch.float)\n",
        "            if mfcc_htk_data.dim() == 1:\n",
        "                mfcc_htk_data = mfcc_htk_data.unsqueeze(-1)  # Reshape to 2D if necessary\n",
        "            feature_list.append(mfcc_htk_data)\n",
        "\n",
        "        # Handle tags_data (check if it's a string or list of strings)\n",
        "        if tags_data is not None:\n",
        "            if isinstance(tags_data, str):\n",
        "                tag_map = {'tag1': 0, 'tag2': 1, 'tag3': 2}  # Example: map your tags to integers\n",
        "                tag_value = tag_map.get(tags_data, -1)  # Use -1 for unknown tags\n",
        "                tag_tensor = torch.tensor([tag_value], dtype=torch.float).unsqueeze(-1)\n",
        "                feature_list.append(tag_tensor)\n",
        "            elif isinstance(tags_data, list):  # If it's a list of tags (strings)\n",
        "                tag_map = {'tag1': 0, 'tag2': 1, 'tag3': 2}  # Example: map your tags to integers\n",
        "                tag_values = [tag_map.get(tag, -1) for tag in tags_data]  # Use -1 for unknown tags\n",
        "                tag_tensor = torch.tensor(tag_values, dtype=torch.float).unsqueeze(-1)\n",
        "                feature_list.append(tag_tensor)\n",
        "\n",
        "        # Pad features to the same size if necessary\n",
        "        feature_lengths = [f.shape[0] for f in feature_list]  # Get the lengths of each feature\n",
        "        max_length = max(feature_lengths)  # Find the maximum length\n",
        "\n",
        "        # Pad the features to have the same length\n",
        "        for i, feature in enumerate(feature_list):\n",
        "            if feature.shape[0] < max_length:\n",
        "                pad_size = max_length - feature.shape[0]\n",
        "                feature_list[i] = torch.nn.functional.pad(feature, (0, 0, 0, pad_size))\n",
        "\n",
        "        # Stack all features together\n",
        "        combined_features = torch.cat(feature_list, dim=-1)\n",
        "\n",
        "        return combined_features"
      ],
      "metadata": {
        "id": "FCxhd0A2S5fQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of DatacosClass usage\n",
        "dataset = DATACOSDataset(data_dir='/content/drive/MyDrive/datacos/da-tacos_coveranalysis_subset_single_files')\n",
        "\n",
        "for i in range(4999, 5001):\n",
        "  # Print the first 5 pairs\n",
        "    song1_data, song2_data, label = dataset[i]\n",
        "    print(f\"Pair {i+1}:\")\n",
        "    print(f\"Song 1 Data: {song1_data.shape}, Song 2 Data: {song2_data.shape}, Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpGlw0G9WHA0",
        "outputId": "0a676de9-9817-4702-e09a-201947bf4675"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pair 5000:\n",
            "Song 1 Data: torch.Size([19086, 38151]), Song 2 Data: torch.Size([15066, 30111]), Label: 0.0\n",
            "Pair 5001:\n",
            "Song 1 Data: torch.Size([15519, 31017]), Song 2 Data: torch.Size([15094, 30167]), Label: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_1 = [dataset[i] for i in range(4000)]  # First 4000 pairs for training\n",
        "train_data_2 = [dataset[i] for i in range(5000, 9000)]  # Next 4000 pairs for training (5000 to 8999)\n",
        "\n",
        "val_data_1 = [dataset[i] for i in range(4000, 5000)]  # 1000 pairs for validation (4000 to 4999)\n",
        "val_data_2 = [dataset[i] for i in range(9000, 10000)]  # 1000 pairs for validation (9000 to 9999)\n",
        "\n",
        "# Combine the training and validation parts\n",
        "train_data = train_data_1 + train_data_2  # Final training data (4000 + 4000)\n",
        "val_data = val_data_1 + val_data_2  # Final validation data (1000 + 1000)\n",
        "\n",
        "# Shuffle both the training and validation datasets\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(val_data)"
      ],
      "metadata": {
        "id": "V9YL7V-HdZeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking in a small set of the dataset\n",
        "\n",
        "train_data_1 = [dataset[i] for i in range(2)]\n",
        "train_data_2 = [dataset[i] for i in range(5, 6)]\n",
        "\n",
        "val_data_1 = [dataset[i] for i in range(4, 5)]\n",
        "val_data_2 = [dataset[i] for i in range(9, 10)]\n",
        "\n",
        "# Combine the training and validation parts\n",
        "train_data = train_data_1 + train_data_2\n",
        "val_data = val_data_1 + val_data_2\n",
        "\n",
        "# Shuffle both the training and validation datasets\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(val_data)"
      ],
      "metadata": {
        "id": "0awx8if9d2ZI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the memory usage of individual samples\n",
        "song1_data, song2_data, label = dataset[0]\n",
        "print(f\"Memory usage of song1_data: {song1_data.element_size() * song1_data.nelement() / (1024 ** 3)} GB\")\n",
        "print(f\"Memory usage of song2_data: {song2_data.element_size() * song2_data.nelement() / (1024 ** 3)} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo6j_vv-ddxU",
        "outputId": "791322e4-ef3a-4852-f942-1fa098a1b1e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage of song1_data: 1.1990559920668602 GB\n",
            "Memory usage of song2_data: 1.4151893481612206 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader objects for both train and validation sets\n",
        "trainloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "validloader = DataLoader(val_data, batch_size=128, shuffle=True)\n",
        "\n",
        "# Check the size of trainloader and validloader\n",
        "print(f\"Trainloader size: {len(trainloader)} batches\")\n",
        "print(f\"Validloader size: {len(validloader)} batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9dXPk9Wdk-k",
        "outputId": "9efb8fae-0f25-4426-f7e6-16b9711c45b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainloader size: 1 batches\n",
            "Validloader size: 1 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Architecture\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "class DrLIM(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Conv2d(in_channels = 1, out_channels = 15, kernel_size = 6, padding = 0, stride = 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.subsampling = nn.MaxPool2d(kernel_size = 3, stride = 3)\n",
        "        self.layer2 = nn.Conv2d(in_channels = 15, out_channels = 30, kernel_size = 9, padding = 0, stride = 1)\n",
        "        # self.relu = nn.ReLU(),\n",
        "        self.fc = nn.Linear(15, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.subsampling(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.reshape(-1, 2, 15)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iL9hP2KFebfc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CL_Loss(x1, x2, Y, m = 1):\n",
        "    Euclidean_norm = torch.sqrt((x1 - x2)**2) # Euclidean Distance\n",
        "    return torch.mean((1-Y).reshape(-1, 1, 1) * 1/2 * Euclidean_norm**2 + Y.reshape(-1, 1, 1) * 1/2 * torch.maximum(torch.Tensor([0]).to(device), m - Euclidean_norm)**2)"
      ],
      "metadata": {
        "id": "zE_fVhg5ehcU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "o6tyzt88esUb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training parameters\n",
        "\n",
        "epochs = 200 # Iteration Number\n",
        "cnt = 0      # early stopping count\n",
        "\n",
        "model = DrLIM().to(device)\n",
        "# criterion = CL_Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001) # Adam Optimizer\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    model = nn.DataParallel(model).to(device)\n",
        "\n",
        "# save train and val Loss\n",
        "train_loss = torch.zeros(epochs)\n",
        "val_loss = torch.zeros(epochs)\n",
        "\n",
        "# save train and val Acc\n",
        "train_acc = torch.zeros(epochs)\n",
        "val_acc = torch.zeros(epochs)\n",
        "\n",
        "# initial loss value is inf.\n",
        "valid_loss_min = np.Inf\n",
        "valid_acc_max = 0"
      ],
      "metadata": {
        "id": "OWDQ0nh3e9Cc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the Model\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train() # train mode\n",
        "\n",
        "    for x1, x2, y in tqdm(trainloader):\n",
        "        y = torch.tensor(y, dtype = torch.float64).to(device)\n",
        "        x1, x2 = x1.to(device), x2.to(device)\n",
        "        optimizer.zero_grad() # optimizer initialization\n",
        "\n",
        "        Gw_x1 = model(x1) # model output of x1\n",
        "        Gw_x2 = model(x2) # model output of x2\n",
        "\n",
        "        # Calculate accuracy\n",
        "        loss = CL_Loss(Gw_x1, Gw_x2, y)\n",
        "        loss.backward() # backward\n",
        "        optimizer.step() # optimizer step\n",
        "        train_loss[epoch] += loss.item() # loss\n",
        "\n",
        "        ans = torch.tensor((Gw_x1[:, 0] < Gw_x1[:, 1]) != (Gw_x2[:, 0] < Gw_x2[:, 1]), dtype=torch.float64) # Similar to Contrastive Leaning Loss\n",
        "        equals = ans == y.reshape(ans.shape)   # calculate acc\n",
        "        train_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item()  # mean\n",
        "\n",
        "    # AVG Loss\n",
        "    train_loss[epoch] /= len(trainloader)\n",
        "    train_acc[epoch] /= len(trainloader)\n",
        "\n",
        "\n",
        "    # valid ,\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x1, x2, y in tqdm(validloader):\n",
        "            y = torch.tensor(y, dtype = torch.float64).to(device)\n",
        "            x1, x2 = x1.to(device), x2.to(device)\n",
        "\n",
        "            Gw_x1 = model(x1)\n",
        "            Gw_x2 = model(x2)\n",
        "\n",
        "            loss = CL_Loss(Gw_x1, Gw_x2, y)\n",
        "            val_loss[epoch] += loss.item() # Loss\n",
        "\n",
        "\n",
        "            ans = torch.tensor((Gw_x1[:, 0] < Gw_x1[:, 1]) != (Gw_x2[:, 0] < Gw_x2[:, 1]), dtype=torch.float64)\n",
        "            equals = ans == y.reshape(ans.shape)\n",
        "            val_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item()  # mean\n",
        "\n",
        "    # validation Loss and accuracy\n",
        "    val_loss[epoch] /= len(validloader)\n",
        "    val_acc[epoch] /= len(validloader)\n",
        "\n",
        "    # print loss and accuracy\n",
        "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "          f\"Train loss: {train_loss[epoch]:.3f}.. \"\n",
        "          f\"Train acc: {train_acc[epoch]:.3f}.. \"\n",
        "          f\"val loss: {val_loss[epoch]:.3f}.. \"\n",
        "          f\"val accuracy: {val_acc[epoch]:.3f}\")\n",
        "\n",
        "    if val_acc[epoch] >= valid_acc_max:\n",
        "        print('Validation acc increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_acc_max,\n",
        "        val_acc[epoch]))\n",
        "        torch.save(model.module.state_dict(), 'DrLIM.pt')\n",
        "        valid_acc_max = val_acc[epoch]\n",
        "\n",
        "        # Early stopping\n",
        "        cnt = 0\n",
        "\n",
        "    # Early stopping and Loss\n",
        "    if cnt >= 10:\n",
        "        print(\"Early Stopping\")\n",
        "        break\n",
        "\n",
        "    cnt+=1 #Loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "e02757857f754f6d841abac3b3fbd387",
            "1e4ce9e48f234e9c83cb4fdbdbb6305a",
            "41d0a4bd74674365a149ef62d02c6008",
            "b054971c6a8a435294835a3702ec9ecb",
            "46b649a9784241f29ac366d400992661",
            "bcc83bb81f51408ca1543406afbc53dc",
            "931f95a4721143398d80acfba08726dc",
            "37bb054353d24d50b8aa9d1e480e1a7a",
            "a264e416ab004ead9c504346c0a32dc7",
            "ed3cac6d3c3e4a9a99db0c9a88a557bd",
            "18ca23e7c75b4ebd8618f5afc1faae4b"
          ]
        },
        "id": "j1u20z-5fHj1",
        "outputId": "e80a32e0-7b80-4a86-f5d2-7cbc8753f400"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e02757857f754f6d841abac3b3fbd387"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [12691, 25362] at entry 0 and [14725, 29430] at entry 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f79fda4ee39d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [12691, 25362] at entry 0 and [14725, 29430] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Potential Transforms - 1.FFT-Downsampling\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'tensor' is our DatasetClass output\n",
        "tensor = np.random.random((20890, 41760))\n",
        "\n",
        "# Apply FFT to get frequency representation\n",
        "fft_tensor = np.fft.fft2(tensor)\n",
        "\n",
        "# Filter out selected frequencies (e.g., keep low frequencies only or whatever wroks with our given task)\n",
        "# For instance, zero out all but the lowest frequencies\n",
        "fft_tensor[100:, :] = 0  # Zero out high frequencies along one dimension\n",
        "fft_tensor[:, 100:] = 0  # Zero out high frequencies along the other dimension\n",
        "\n",
        "# Apply inverse FFT to get the downsampled tensor in spatial domain\n",
        "downsampled_tensor = np.fft.ifft2(fft_tensor)\n"
      ],
      "metadata": {
        "id": "mCk06-rtrMxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Potential Transforms - 2.PCA\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `tensor` is your original 2D tensor (e.g., [20890, 41760])\n",
        "tensor = np.random.random((20890, 41760))\n",
        "\n",
        "# Apply FFT to the tensor to get the frequency domain representation\n",
        "fft_tensor = np.fft.fft2(tensor)\n",
        "\n",
        "# Flatten the FFT result to apply PCA\n",
        "fft_flattened = fft_tensor.flatten().reshape(-1, 1)\n",
        "\n",
        "# Perform PCA to reduce dimensionality (e.g., keeping top 10 components)\n",
        "pca = PCA(n_components=10)\n",
        "pca_result = pca.fit_transform(fft_flattened)\n",
        "\n",
        "# Reconstruct the downsampled tensor using the inverse PCA transformation\n",
        "downsampled_tensor = pca.inverse_transform(pca_result)"
      ],
      "metadata": {
        "id": "mp_OJ8HWrPQf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}